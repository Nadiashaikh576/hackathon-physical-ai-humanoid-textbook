# Chapter 1: Voice-to-Action â€” Speech as Robot Input

**Learning Progress Indicator**: [====      ] 40% complete

This chapter introduces the concept of voice-to-action conversion in humanoid robotics. We'll explore why voice is a natural interface for humanoids, examine speech-to-text technologies like OpenAI Whisper, and understand how spoken commands are converted to structured intent that robots can execute.

## Topics Covered

In this chapter, you will learn about:
- Why voice is a natural interface for humanoids
- Speech-to-text using OpenAI Whisper
- From spoken commands to structured intent
- Integrating voice input with ROS 2 systems
- Limitations and latency considerations

## Why This Matters

Voice interfaces are crucial for humanoid robots because they enable natural human-robot interaction. Understanding the voice-to-action pipeline is foundational for more advanced topics like cognitive planning with LLMs.

## Sections

1. [Why voice is a natural interface for humanoids](../chapter-1-voice-to-action/voice-natural-interface.md)
2. [Speech-to-text using OpenAI Whisper](../chapter-1-voice-to-action/speech-to-text.md)
3. [From spoken commands to structured intent](../chapter-1-voice-to-action/commands-to-intent.md)
4. [Integrating voice input with ROS 2 systems](../chapter-1-voice-to-action/ros2-integration.md)
5. [Limitations and latency considerations](../chapter-1-voice-to-action/limitations-latency.md)

![Voice-to-Action Pipeline](/img/voice-to-action-pipeline.png)
*Figure 4.2: Overview of the voice-to-action conversion pipeline showing how speech is processed into executable robot actions.*

Let's begin by understanding why voice is such a natural interface for humanoids.
