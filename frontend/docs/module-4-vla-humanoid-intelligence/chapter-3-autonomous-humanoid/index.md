# Chapter 3: Capstone — The Autonomous Humanoid

**Learning Progress Indicator**: [==========] 100% complete

This chapter brings together all the concepts from the previous chapters to present a complete end-to-end VLA pipeline. We'll examine how perception, planning, navigation, and manipulation work together to create autonomous humanoid behavior that can execute multi-step tasks in dynamic environments.

## Topics Covered

In this chapter, you will learn about:
- End-to-end VLA pipeline overview
- Perception → planning → navigation → manipulation
- Object identification using computer vision
- Executing multi-step tasks in dynamic environments
- Connecting all previous modules into one system

## Bringing It All Together

This chapter represents the culmination of the module, showing how voice-to-action conversion and cognitive planning combine with perception and action systems to create complete autonomous behavior.

## Sections

1. [End-to-end VLA pipeline overview](../chapter-3-autonomous-humanoid/end-to-end-pipeline.md)
2. [Perception → planning → navigation → manipulation](../chapter-3-autonomous-humanoid/perception-planning-navigation-manipulation.md)
3. [Object identification using computer vision](../chapter-3-autonomous-humanoid/object-identification.md)
4. [Executing multi-step tasks in dynamic environments](../chapter-3-autonomous-humanoid/multi-step-tasks.md)
5. [Connecting all previous modules into one system](../chapter-3-autonomous-humanoid/module-integration.md)

![Complete Autonomous System](/img/complete-autonomous-system.png)
*Figure 4.4: Overview of the complete autonomous humanoid system showing how all components integrate to enable autonomous behavior.*

Let's begin by understanding the complete end-to-end VLA pipeline.
